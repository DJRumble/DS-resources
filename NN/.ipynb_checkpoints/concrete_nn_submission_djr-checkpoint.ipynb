{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this course project, you will build a regression model using the deep learning Keras library, and then you will experiment with increasing the number of training epochs and changing number of hidden layers and you will see how changing these parameters impacts the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1030, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "\n",
    "print(concrete_data.shape)\n",
    "\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Build a baseline model (5 marks) \n",
    "\n",
    "Use the Keras library to build a neural network with the following:\n",
    "\n",
    "- One hidden layer of 10 nodes, and a ReLU activation function\n",
    "\n",
    "- Use the adam optimizer and the mean squared error  as the loss function.\n",
    "\n",
    "1. Randomly split the data into a training and test sets by holding 30% of the data for testing. You can use the train_test_splithelper function from Scikit-learn.\n",
    "\n",
    "2. Train the model on the training data using 50 epochs.\n",
    "\n",
    "3. Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn.\n",
    "\n",
    "4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors.\n",
    "\n",
    "5. Report the mean and the standard deviation of the mean squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regression model\n",
    "def regression_model_A(n_cols):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))    \n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_A(concrete_data):\n",
    "    \n",
    "    concrete_data_columns = concrete_data.columns\n",
    "\n",
    "    predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "    target = concrete_data['Strength'] # Strength column\n",
    "    \n",
    "    #reduce to requested columns\n",
    "    predictors_labels = ['Cement'\n",
    "                        ,'Blast Furnace Slag'\n",
    "                        ,'Fly Ash'\n",
    "                        ,'Water'\n",
    "                        ,'Superplasticizer'\n",
    "                        ,'Coarse Aggregate'\n",
    "                        ,'Fine Aggregate']\n",
    "\n",
    "    predictors = predictors[predictors_labels]    \n",
    "\n",
    "    #normalise and save number of cols as variable\n",
    "    #predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "\n",
    "    n_cols = predictors.shape[1] # number of predictors    \n",
    "    \n",
    "    model_A = regression_model_A(n_cols)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=42)    \n",
    "\n",
    "    #Fit model\n",
    "    model_A.fit(X_train, y_train, validation_split=0.3, epochs=50, verbose=0)\n",
    "    \n",
    "    y_pred = model_A.predict(X_test,verbose=2).reshape(len(X_test),)\n",
    "    \n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    \n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:17<00:00,  1.55s/it]\n"
     ]
    }
   ],
   "source": [
    "mse_list_A = []\n",
    "\n",
    "for i in tqdm(np.arange(0,50)):\n",
    "    mse_list_A.append(part_A(concrete_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean MSE is 483.8468355505741\n",
      "The std MSE is 385.4629868188446\n"
     ]
    }
   ],
   "source": [
    "print(f'The mean MSE is {np.mean(mse_list_A)}')\n",
    "print(f'The std MSE is {np.std(mse_list_A)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Normalize the data (5 marks) \n",
    "\n",
    "Repeat Part A but use a normalized version of the data. Recall that one way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regression model\n",
    "def regression_model_B(n_cols):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))    \n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_B(concrete_data):\n",
    "    \n",
    "    concrete_data_columns = concrete_data.columns\n",
    "\n",
    "    predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "    target = concrete_data['Strength'] # Strength column\n",
    "    \n",
    "    #reduce to requested columns\n",
    "    predictors_labels = ['Cement'\n",
    "                        ,'Blast Furnace Slag'\n",
    "                        ,'Fly Ash'\n",
    "                        ,'Water'\n",
    "                        ,'Superplasticizer'\n",
    "                        ,'Coarse Aggregate'\n",
    "                        ,'Fine Aggregate']\n",
    "\n",
    "    predictors = predictors[predictors_labels]    \n",
    "\n",
    "    #normalise and save number of cols as variable\n",
    "    predictors = (predictors - predictors.mean()) / predictors.std()\n",
    "\n",
    "    n_cols = predictors.shape[1] # number of predictors    \n",
    "    \n",
    "    model_B = regression_model_B(n_cols)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=42)    \n",
    "\n",
    "    #Fit model\n",
    "    model_B.fit(X_train, y_train, validation_split=0.3, epochs=50, verbose=0)\n",
    "    \n",
    "    y_pred = model_B.predict(X_test,verbose=2).reshape(len(X_test),)\n",
    "    \n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    \n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:23<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean MSE is 660.3737798966272\n",
      "The std MSE is 115.79833496649705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mse_list_B = []\n",
    "\n",
    "for i in tqdm(np.arange(0,50)):\n",
    "    mse_list_B.append(part_B(concrete_data))\n",
    "\n",
    "print(f'The mean MSE is {np.mean(mse_list_B)}')\n",
    "print(f'The std MSE is {np.std(mse_list_B)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Increate the number of epochs (5 marks)\n",
    "\n",
    "Repeat Part B but use 100 epochs this time for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regression model\n",
    "def regression_model_C(n_cols):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))    \n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_C(concrete_data):\n",
    "    \n",
    "    concrete_data_columns = concrete_data.columns\n",
    "\n",
    "    predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "    target = concrete_data['Strength'] # Strength column\n",
    "    \n",
    "    #reduce to requested columns\n",
    "    predictors_labels = ['Cement'\n",
    "                        ,'Blast Furnace Slag'\n",
    "                        ,'Fly Ash'\n",
    "                        ,'Water'\n",
    "                        ,'Superplasticizer'\n",
    "                        ,'Coarse Aggregate'\n",
    "                        ,'Fine Aggregate']\n",
    "\n",
    "    predictors = predictors[predictors_labels]    \n",
    "\n",
    "    #normalise and save number of cols as variable\n",
    "    predictors = (predictors - predictors.mean()) / predictors.std()\n",
    "\n",
    "    n_cols = predictors.shape[1] # number of predictors    \n",
    "    \n",
    "    model_C = regression_model_C(n_cols)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=42)    \n",
    "\n",
    "    #Fit model\n",
    "    model_C.fit(X_train, y_train, validation_split=0.3, epochs=100, verbose=0)\n",
    "    \n",
    "    y_pred = model_C.predict(X_test,verbose=2).reshape(len(X_test),)\n",
    "    \n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    \n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:17<00:00,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean MSE is 237.60909202813764\n",
      "The std MSE is 41.62791762438415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mse_list_C = []\n",
    "\n",
    "for i in tqdm(np.arange(0,50)):\n",
    "    mse_list_C.append(part_C(concrete_data))\n",
    "\n",
    "print(f'The mean MSE is {np.mean(mse_list_C)}')\n",
    "print(f'The std MSE is {np.std(mse_list_C)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Increase the number of hidden layers (5 marks)\n",
    "\n",
    "Repeat part B but use a neural network with the following instead:\n",
    "\n",
    "- Three hidden layers, each of 10 nodes and ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regression model\n",
    "def regression_model_D(n_cols):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(10, activation='relu'))    \n",
    "    model.add(Dense(10, activation='relu'))          \n",
    "    model.add(Dense(1))    \n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_D(concrete_data):\n",
    "    \n",
    "    concrete_data_columns = concrete_data.columns\n",
    "\n",
    "    predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "    target = concrete_data['Strength'] # Strength column\n",
    "    \n",
    "    #reduce to requested columns\n",
    "    predictors_labels = ['Cement'\n",
    "                        ,'Blast Furnace Slag'\n",
    "                        ,'Fly Ash'\n",
    "                        ,'Water'\n",
    "                        ,'Superplasticizer'\n",
    "                        ,'Coarse Aggregate'\n",
    "                        ,'Fine Aggregate']\n",
    "\n",
    "    predictors = predictors[predictors_labels]    \n",
    "\n",
    "    #normalise and save number of cols as variable\n",
    "    predictors = (predictors - predictors.mean()) / predictors.std()\n",
    "\n",
    "    n_cols = predictors.shape[1] # number of predictors    \n",
    "    \n",
    "    model_D = regression_model_D(n_cols)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=42)    \n",
    "\n",
    "    #Fit model\n",
    "    model_D.fit(X_train, y_train, validation_split=0.3, epochs=100, verbose=0)\n",
    "    \n",
    "    y_pred = model_D.predict(X_test,verbose=2).reshape(len(X_test),)\n",
    "    \n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    \n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:57<00:00,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean MSE is 163.82388525992357\n",
      "The std MSE is 4.0307253715958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mse_list_D = []\n",
    "\n",
    "for i in tqdm(np.arange(0,50)):\n",
    "    mse_list_D.append(part_D(concrete_data))\n",
    "\n",
    "print(f'The mean MSE is {np.mean(mse_list_D)}')\n",
    "print(f'The std MSE is {np.std(mse_list_D)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
