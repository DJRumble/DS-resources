{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: wrapt in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.11.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorrec\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/14/608abc1c669caf7f2f9a7a13d237bd3f58df08ed71b8eb4c2d756b025adf/tensorrec-0.26.2-py3-none-any.whl\n",
      "Collecting six==1.11.0 (from tensorrec)\n",
      "  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.14.1 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorrec) (1.16.4)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorrec) (1.3.0)\n",
      "Requirement already satisfied: tensorflow>=1.7.0 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorrec) (1.14.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow>=1.7.0->tensorrec) (0.8.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow>=1.7.0->tensorrec) (1.0.8)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow>=1.7.0->tensorrec) (0.1.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow>=1.7.0->tensorrec) (1.11.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow>=1.7.0->tensorrec) (3.11.1)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow>=1.7.0->tensorrec) (1.14.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow>=1.7.0->tensorrec) (0.8.1)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow>=1.7.0->tensorrec) (1.14.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow>=1.7.0->tensorrec) (1.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow>=1.7.0->tensorrec) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow>=1.7.0->tensorrec) (0.33.6)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow>=1.7.0->tensorrec) (0.2.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorflow>=1.7.0->tensorrec) (1.25.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow>=1.7.0->tensorrec) (2.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from protobuf>=3.6.1->tensorflow>=1.7.0->tensorrec) (41.2.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow>=1.7.0->tensorrec) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\612987997\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow>=1.7.0->tensorrec) (3.1.1)\n",
      "Installing collected packages: six, tensorrec\n",
      "  Found existing installation: six 1.12.0\n",
      "    Uninstalling six-1.12.0:\n",
      "      Successfully uninstalled six-1.12.0\n",
      "Successfully installed six-1.11.0 tensorrec-0.26.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install --upgrade pip\n",
    "#!pip3 uninstall -y numpy\n",
    "#!pip3 install --user --upgrade --force-reinstall tensorflow-gpu==1.1.0 \n",
    "!pip install --user --upgrade wrapt\n",
    "!pip install tensorrec \n",
    "!pip install fuzzywuzzy\n",
    "!pip install python-Levenshtein\n",
    "#!pip3 install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "import random\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import boto3\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from io import BytesIO, TextIOWrapper\n",
    "import tensorrec\n",
    "import io\n",
    "import os\n",
    "from datetime import date\n",
    "import math\n",
    "from fuzzywuzzy import  fuzz\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>REFERENCE_DATE</th>\n",
       "      <th>SUB_ID</th>\n",
       "      <th>MARKETING_NAME</th>\n",
       "      <th>INTERACTIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NOT IMPORTANT</td>\n",
       "      <td>1006</td>\n",
       "      <td>SAMSUNG GALAXY NOTE 8 LTE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NOT IMPORTANT</td>\n",
       "      <td>1016</td>\n",
       "      <td>SONY XPERIA XA LTE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NOT IMPORTANT</td>\n",
       "      <td>1020</td>\n",
       "      <td>SAMSUNG I9070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NOT IMPORTANT</td>\n",
       "      <td>1025</td>\n",
       "      <td>APPLE IPHONE 5C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NOT IMPORTANT</td>\n",
       "      <td>1027</td>\n",
       "      <td>SAMSUNG GALAXY S10 LTE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 REFERENCE_DATE  SUB_ID             MARKETING_NAME  INTERACTIONS\n",
       "0           0  NOT IMPORTANT    1006  SAMSUNG GALAXY NOTE 8 LTE             1\n",
       "1           1  NOT IMPORTANT    1016         SONY XPERIA XA LTE             1\n",
       "2           2  NOT IMPORTANT    1020              SAMSUNG I9070             1\n",
       "3           3  NOT IMPORTANT    1025            APPLE IPHONE 5C             1\n",
       "4           4  NOT IMPORTANT    1027     SAMSUNG GALAXY S10 LTE             1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To change to Athena when we have the data in there -- to be replaced with non-static when pipeline is implemented \n",
    "bucket = \"bt-data-science-playground\"\n",
    "file_name = \"GP/device_hist3.csv.gz\"\n",
    " \n",
    "s3 = boto3.client('s3') \n",
    "# 's3' is a key word. create connection to S3 using default config and all buckets within S3\n",
    "\n",
    "obj = s3.get_object(Bucket= bucket, Key= file_name) \n",
    "# get object and file (key) from bucket\n",
    "\n",
    "dataset = pd.read_csv(gzip.open(obj['Body']),encoding = \"ISO-8859-1\",\n",
    "                      dtype = {'REFERENCE_DATE':'str',\n",
    "                               'SUB_ID':'int',\n",
    "                               'MARKETING_NAME':'str',\n",
    "                               'INTERACTIONS':'int'\n",
    "                                }) # 'Body' is a key word\n",
    "\n",
    "dataset['MARKETING_NAME'] = dataset['MARKETING_NAME'].map(lambda x: x.rstrip())\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "974"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine popular devices with at least 100 sales\n",
    "pop_items = pd.DataFrame(dataset.MARKETING_NAME.value_counts())\n",
    "pop_items2 = pop_items[pop_items.MARKETING_NAME > 100]\n",
    "pop_items2 = pop_items2.reset_index()\n",
    "\n",
    "pop_items_l = list(pop_items2.iloc[:,0])\n",
    "len(pop_items_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18701718 entries, 0 to 18723356\n",
      "Data columns (total 5 columns):\n",
      "Unnamed: 0        int64\n",
      "REFERENCE_DATE    object\n",
      "SUB_ID            int64\n",
      "MARKETING_NAME    object\n",
      "INTERACTIONS      int64\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 856.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#Reduce Dataset to contain only the popular items \n",
    "dataset = dataset[dataset['MARKETING_NAME'].isin(pop_items_l)]\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27663 entries, 0 to 27662\n",
      "Data columns (total 3 columns):\n",
      "TAC               27663 non-null int64\n",
      "MARKETING_NAME    27663 non-null object\n",
      "YEAR_OUT          27077 non-null float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 648.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#Import Device Launch Year -- to be replaced with non-static when pipeline is implemented\n",
    "\n",
    "bucket='bt-data-science-playground' # Or whatever you called your bucket\n",
    "data_key = 'GP/device_list_all.csv' # Where the file is within your bucket\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "device_specs = pd.read_csv(data_location)\n",
    "device_specs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MARKETING_NAME</th>\n",
       "      <th>YEAR_OUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-LINK TELECOM INTERNATIONAL CO LIMITED CUBOT ...</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABTEL JOINT STOCK COMPANY Q SMART QS08</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACER INCORPORATED E110</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACER INCORPORATED E320 EU</td>\n",
       "      <td>2011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACER INCORPORATED LIQUID JADE Z</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      MARKETING_NAME  YEAR_OUT\n",
       "0  A-LINK TELECOM INTERNATIONAL CO LIMITED CUBOT ...    2015.0\n",
       "1             ABTEL JOINT STOCK COMPANY Q SMART QS08    2014.0\n",
       "2                             ACER INCORPORATED E110    2010.0\n",
       "3                          ACER INCORPORATED E320 EU    2011.0\n",
       "4                    ACER INCORPORATED LIQUID JADE Z    2015.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some Devices come against multiple TACs but year is the same so we're removing duplicates \n",
    "max_device_specs = pd.DataFrame(device_specs.groupby(['MARKETING_NAME'])['YEAR_OUT'].max()).reset_index()\n",
    "max_device_specs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TAC</th>\n",
       "      <th>MARKETING_NAME</th>\n",
       "      <th>DEVICE_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35863407</td>\n",
       "      <td>APPLE IPHONE SE</td>\n",
       "      <td>Smartphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35664508</td>\n",
       "      <td>APPLE IPHONE 6</td>\n",
       "      <td>Smartphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35930506</td>\n",
       "      <td>APPLE IPHONE 6</td>\n",
       "      <td>Smartphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35634010</td>\n",
       "      <td>APPLE IPHONE 11</td>\n",
       "      <td>Smartphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35207207</td>\n",
       "      <td>APPLE IPAD AIR 2</td>\n",
       "      <td>Smartphone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TAC    MARKETING_NAME DEVICE_TYPE\n",
       "0  35863407   APPLE IPHONE SE  Smartphone\n",
       "1  35664508    APPLE IPHONE 6  Smartphone\n",
       "2  35930506    APPLE IPHONE 6  Smartphone\n",
       "3  35634010   APPLE IPHONE 11  Smartphone\n",
       "4  35207207  APPLE IPAD AIR 2  Smartphone"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Device Type - Smartphone, Tablet, Wearable -- to be replaced with non-static when pipeline is implemented\n",
    "\n",
    "bucket='bt-data-science-playground' # Or whatever you called your bucket\n",
    "data_key = 'GP/device_list_type.csv' # Where the file is within your bucket\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "device_type = pd.read_csv(data_location)\n",
    "device_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MARKETING_NAME</th>\n",
       "      <th>DEVICE_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-LINK TELECOM INTERNATIONAL CO LIMITED CUBOT ...</td>\n",
       "      <td>Smartphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABTEL JOINT STOCK COMPANY Q SMART QS08</td>\n",
       "      <td>Smartphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACER INCORPORATED LIQUID JADE Z</td>\n",
       "      <td>Smartphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACER INCORPORATED LIQUID Z4</td>\n",
       "      <td>Smartphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALCATEL \"PIXI46\"\"4GANDROID\"</td>\n",
       "      <td>Smartphone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      MARKETING_NAME DEVICE_TYPE\n",
       "0  A-LINK TELECOM INTERNATIONAL CO LIMITED CUBOT ...  Smartphone\n",
       "1             ABTEL JOINT STOCK COMPANY Q SMART QS08  Smartphone\n",
       "2                    ACER INCORPORATED LIQUID JADE Z  Smartphone\n",
       "3                        ACER INCORPORATED LIQUID Z4  Smartphone\n",
       "4                        ALCATEL \"PIXI46\"\"4GANDROID\"  Smartphone"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Same issue with TACs so we dedupe\n",
    "max_product_type =  pd.DataFrame(device_type.groupby(['MARKETING_NAME'])['DEVICE_TYPE'].max()).reset_index()\n",
    "max_product_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TAC</th>\n",
       "      <th>MARKETING_NAME</th>\n",
       "      <th>IOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35299609</td>\n",
       "      <td>APPLE IPHONE 8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35233608</td>\n",
       "      <td>SAMSUNG GALAXY J7 PRIME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35285209</td>\n",
       "      <td>SONY XPERIAXA2ULTRA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35182007</td>\n",
       "      <td>SAMSUNG GALAXY A3 LTE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35195208</td>\n",
       "      <td>SAMSUNG GALAXY S7 G930F LTE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TAC               MARKETING_NAME  IOS\n",
       "0  35299609               APPLE IPHONE 8    1\n",
       "1  35233608      SAMSUNG GALAXY J7 PRIME    0\n",
       "2  35285209          SONY XPERIAXA2ULTRA    0\n",
       "3  35182007        SAMSUNG GALAXY A3 LTE    0\n",
       "4  35195208  SAMSUNG GALAXY S7 G930F LTE    0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import OS type\n",
    "\n",
    "bucket='bt-data-science-playground' # Or whatever you called your bucket\n",
    "data_key = 'GP/device_list_os.csv' # Where the file is within your bucket\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "device_os = pd.read_csv(data_location)\n",
    "device_os['MARKETING_NAME'] = device_os['MARKETING_NAME'].map(lambda x: x.rstrip())\n",
    "device_os.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MARKETING_NAME</th>\n",
       "      <th>IOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-LINK TELECOM INTERNATIONAL CO LIMITED CUBOT ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABTEL JOINT STOCK COMPANY Q SMART QS08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACER INCORPORATED E110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACER INCORPORATED E320 EU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACER INCORPORATED LIQUID JADE Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      MARKETING_NAME  IOS\n",
       "0  A-LINK TELECOM INTERNATIONAL CO LIMITED CUBOT ...    0\n",
       "1             ABTEL JOINT STOCK COMPANY Q SMART QS08    0\n",
       "2                             ACER INCORPORATED E110    0\n",
       "3                          ACER INCORPORATED E320 EU    0\n",
       "4                    ACER INCORPORATED LIQUID JADE Z    0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Same issue with TACs so we dedupe\n",
    "max_product_os =  pd.DataFrame(device_os.groupby(['MARKETING_NAME'])['IOS'].max()).reset_index()\n",
    "max_product_os.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>IOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code  IOS\n",
       "0     0  0.0\n",
       "1     1  NaN\n",
       "2     2  0.0\n",
       "3     3  0.0\n",
       "4     4  0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Device type by code instead of Marketing Name \n",
    "max_product_os =  pd.DataFrame(dataset.groupby(['code'])['IOS'].max()).reset_index()\n",
    "max_product_os.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>DEVICE_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tablet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Tablet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code DEVICE_TYPE\n",
       "0     0         NaN\n",
       "1     1         NaN\n",
       "2     2         NaN\n",
       "3     3      Tablet\n",
       "4     4      Tablet"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Device type by code instead of Marketing Name \n",
    "max_product_type =  pd.DataFrame(dataset.groupby(['code'])['DEVICE_TYPE'].max()).reset_index()\n",
    "max_product_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_user</th>\n",
       "      <th>YEAR_OUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code_user  YEAR_OUT\n",
       "0          0    2017.0\n",
       "1          1    2016.0\n",
       "2          2    2012.0\n",
       "3          3    2013.0\n",
       "4          4    2019.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Year of Launch for each user so we can take the latest device date for each user \n",
    "max_cust_year_prod =  pd.DataFrame(dataset.groupby(['code_user'])['YEAR_OUT'].max()).reset_index()\n",
    "max_cust_year_prod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>YEAR_OUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code  YEAR_OUT\n",
       "0     0    2011.0\n",
       "1     1       NaN\n",
       "2     2    2017.0\n",
       "3     3    2018.0\n",
       "4     4    2018.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take Year of Launch by device to compare \n",
    "max_dev_year_prod =  pd.DataFrame(dataset.groupby(['code'])['YEAR_OUT'].max()).reset_index()\n",
    "max_dev_year_prod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>INTERACTIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code  INTERACTIONS\n",
       "0     0           301\n",
       "1     1          3275\n",
       "2     2          1991\n",
       "3     3          9977\n",
       "4     4           659"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take Popular Devices\n",
    "pop_devices =  pd.DataFrame(dataset.groupby(['code'])['INTERACTIONS'].sum()).reset_index()\n",
    "pop_devices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>INTERACTIONS</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>1488364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>1096496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>991567</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>731323</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>710184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code  INTERACTIONS  Popular\n",
       "65    65       1488364        1\n",
       "63    63       1096496        1\n",
       "70    70        991567        1\n",
       "60    60        731323        1\n",
       "67    67        710184        1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_devices = pop_devices.sort_values(by = 'INTERACTIONS', ascending = False)\n",
    "pop_devices2 = pop_devices.head(100)\n",
    "pop_devices2['Popular'] = 1 \n",
    "pop_devices2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_user</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code_user  code\n",
       "0          0   728\n",
       "1          1   911\n",
       "2          2   795\n",
       "3          3    58\n",
       "4          4   732"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataset of all existing products by user in last 2 years so we can remove them later \n",
    "existing_products = dataset[['code_user','code']]\n",
    "#existing_products['code'] = str(existing_products['code'])\n",
    "existing_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_user</th>\n",
       "      <th>IOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code_user  IOS\n",
       "0          0  0.0\n",
       "1          1  0.0\n",
       "2          2  0.0\n",
       "3          3  1.0\n",
       "4          4  0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Year of Launch for each user so we can take the latest device date for each user \n",
    "max_cust_os =  pd.DataFrame(dataset.groupby(['code_user'])['IOS'].max()).reset_index()\n",
    "max_cust_os.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring chunk size \n",
    "n = 3000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk score dataset \n",
    "list_df = [dataset[i:i+n] for i in range(0,dataset.shape[0],n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of chunks \n",
    "max_len_list = math.ceil(len(dataset)/n) \n",
    "max_len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_creation_and_scoring(num_reccs):\n",
    "    #Function to explode a comma \n",
    "\n",
    "    def explode(df, lst_cols, fill_value='', preserve_index=False):\n",
    "        # make sure `lst_cols` is list-alike\n",
    "        if (lst_cols is not None\n",
    "            and len(lst_cols) > 0\n",
    "            and not isinstance(lst_cols, (list, tuple, np.ndarray, pd.Series))):\n",
    "            lst_cols = [lst_cols]\n",
    "        # all columns except `lst_cols`\n",
    "        idx_cols = df.columns.difference(lst_cols)\n",
    "        # calculate lengths of lists\n",
    "        lens = df[lst_cols[0]].str.len()\n",
    "        # preserve original index values    \n",
    "        idx = np.repeat(df.index.values, lens)\n",
    "        # create \"exploded\" DF\n",
    "        res = (pd.DataFrame({\n",
    "                    col:np.repeat(df[col].values, lens)\n",
    "                    for col in idx_cols},\n",
    "                    index=idx)\n",
    "                 .assign(**{col:np.concatenate(df.loc[lens>0, col].values)\n",
    "                                for col in lst_cols}))\n",
    "        # append those rows that have empty lists\n",
    "        if (lens == 0).any():\n",
    "            # at least one list in cells is empty\n",
    "            res = (res.append(df.loc[lens==0, idx_cols], sort=False)\n",
    "                      .fillna(fill_value))\n",
    "        # revert the original index order\n",
    "        res = res.sort_index()\n",
    "        # reset index if requested\n",
    "        if not preserve_index:        \n",
    "            res = res.reset_index(drop=True)\n",
    "        return res\n",
    "\n",
    "    for i in range(0,max_len_list): #loops through dataset chunks to create model & score for each:\n",
    "        var = os.path.exists(\"George/Model_Parts/recommender_\"+str(i)+\"/\")\n",
    "        if not var  :\n",
    "            print('For batch #',i)\n",
    "            #Transforms IDs to numeric\n",
    "            list_df[i].SUB_ID = pd.to_numeric(list_df[i].SUB_ID)\n",
    "            \n",
    "            print('Step 1')\n",
    "            print(list_df[i].head())\n",
    "            \n",
    "            #Transforms product to categorical\n",
    "            list_df[i].MARKETING_NAME = pd.Categorical(list_df[i].MARKETING_NAME)\n",
    "            \n",
    "            #Lists products\n",
    "            list_df[i]['code'] = list_df[i].MARKETING_NAME.cat.codes\n",
    "            #dataset['code'] = dataset['code'].apply(pd.to_numeric) + 1 \n",
    "            #dataset.code = dataset.code.astype(int)\n",
    "            print('Step 2')\n",
    "            print(list_df[i]['code'].sort_values())\n",
    "            print(list_df[i].info())\n",
    "\n",
    "            #Encodes product\n",
    "            encodings_product = list_df[i][['MARKETING_NAME', 'code']]\n",
    "            print('Step 3')\n",
    "            print(encodings_product.info())\n",
    "\n",
    "            encodings_product = encodings_product.drop_duplicates()\n",
    "\n",
    "            print('Step 4')\n",
    "            print(encodings_product.sort_values('code'))\n",
    "\n",
    "            #Lists SUBs\n",
    "            list_df[i].SUB_ID = pd.Categorical(list_df[i].SUB_ID)\n",
    "            list_df[i]['code_user'] = list_df[i].SUB_ID.cat.codes\n",
    "            #dataset['code_user'] = dataset['code_user'].apply(pd.to_numeric) + 1 \n",
    "            #dataset.code_user = dataset.code_user.astype(int)\n",
    "            print('Step 5')\n",
    "            print(list_df[i]['code_user'].sort_values())\n",
    "\n",
    "            #Encodes SUBs\n",
    "            encodings_user = list_df[i][['SUB_ID', 'code_user']]\n",
    "            print('Step 6')\n",
    "            print(encodings_user.info())\n",
    "\n",
    "            encodings_user = encodings_user.drop_duplicates()\n",
    "\n",
    "            print('Step 7')\n",
    "            print(encodings_user.sort_values('SUB_ID'))\n",
    "\n",
    "\n",
    "            del list_df[i]['MARKETING_NAME']\n",
    "            del list_df[i]['code_user']\n",
    "            print('Step 8')\n",
    "            print(list_df[i].head())\n",
    "\n",
    "            #Arranges dataframe in correct format\n",
    "            list_df[i] = list_df[i][['SUB_ID', 'code', 'INTERACTIONS', 'REFERENCE_DATE']]\n",
    "            print('Step 9')\n",
    "            print(list_df[i].tail(2))\n",
    "\n",
    "            dataset2 = [list_df[i].columns.values.tolist()] + list_df[i].values.tolist()\n",
    "            dataset_header = dataset2.pop(0)\n",
    "            \n",
    "            # Maps users & Products\n",
    "            \n",
    "            dataset_to_internal_user_ids = defaultdict(lambda: len(dataset_to_internal_user_ids))\n",
    "            dataset_to_internal_item_ids = defaultdict(lambda: len(dataset_to_internal_item_ids))\n",
    "            for row in dataset2:\n",
    "                row[0] = dataset_to_internal_user_ids[int(row[0])]\n",
    "                row[1] = dataset_to_internal_item_ids[int(row[1])]\n",
    "                row[2] = float(row[2])\n",
    "            n_users = len(dataset_to_internal_user_ids)\n",
    "            n_items = len(dataset_to_internal_item_ids)\n",
    "\n",
    "            print('Step 10')\n",
    "            # Look at an example raw rating\n",
    "            print(\"Raw ratings example:\\n{}\\n{}\".format(dataset_header, dataset2[0]))\n",
    "\n",
    "            # Shuffle the ratings and split them in to train/test sets 80%/20%\n",
    "            random.shuffle(dataset2)  # Shuffles the list in-place\n",
    "            cutoff = int(.8 * len(dataset2))\n",
    "            train_ratings = dataset2[:cutoff]\n",
    "            test_ratings = dataset2[cutoff:]\n",
    "            print('Step 11')\n",
    "            print(\"{} train ratings, {} test ratings\".format(len(train_ratings), len(test_ratings)))\n",
    "\n",
    "\n",
    "            # This method converts a list of (user, item, rating, time) to a sparse matrix\n",
    "            def interactions_list_to_sparse_matrix(interactions):\n",
    "                users_column, items_column, ratings_column, _ = zip(*interactions)\n",
    "                return sparse.coo_matrix((ratings_column, (users_column, items_column)),\n",
    "                                         shape=(n_users, n_items))\n",
    "\n",
    "            print('Step 12')\n",
    "            # Create sparse matrices of interaction data\n",
    "            sparse_train_ratings = interactions_list_to_sparse_matrix(train_ratings)\n",
    "            sparse_test_ratings = interactions_list_to_sparse_matrix(test_ratings)\n",
    "\n",
    "            print('Step 13')\n",
    "            # Construct indicator features for users and items\n",
    "            user_indicator_features = sparse.identity(n_users)\n",
    "            item_indicator_features = sparse.identity(n_items)\n",
    "\n",
    "            \n",
    "\n",
    "            #This method consumes item ranks for each user and prints out recall@10 train/test metrics\n",
    "            def check_results(ranks):\n",
    "                train_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "                    test_interactions=sparse_train_ratings,\n",
    "                    predicted_ranks=ranks,\n",
    "                    k=10\n",
    "                ).mean()\n",
    "                test_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "                    test_interactions=sparse_test_ratings,\n",
    "                    predicted_ranks=ranks,\n",
    "                    k=10\n",
    "                ).mean()\n",
    "                today = date.today()\n",
    "                d1 = today.strftime(\"%d/%m/%Y\")\n",
    "                print(\"On Date: \",str(d1),\" For Batch #\", i , \" Recall at 10: Train: {:.4f} Test: {:.4f}\".format(train_recall_at_10,\n",
    "                                                                        test_recall_at_10),file=open('accuracies.txt','a'))\n",
    "            print('Step 14')\n",
    "\n",
    "            from tensorflow.keras.models import Sequential\n",
    "            # Let's try a new loss function: WMRB\n",
    "            print(\"Training collaborative filter with WMRB loss\")\n",
    "            ranking_cf_model = tensorrec.TensorRec(n_components=5,\n",
    "                                                   loss_graph=tensorrec.loss_graphs.WMRBLossGraph())\n",
    "            ranking_cf_model.fit(interactions=sparse_train_ratings,\n",
    "                                 user_features=user_indicator_features,\n",
    "                                 item_features=item_indicator_features,\n",
    "                                 n_sampled_items=int(n_items * .01),\n",
    "                                 user_batch_size= 100000)\n",
    "\n",
    "            print('Step 15')\n",
    "            # Check the results of the WMRB MF CF model\n",
    "            print(\"WMRB matrix factorization collaborative filter:\")\n",
    "            predicted_ranks = ranking_cf_model.predict_rank(user_features=user_indicator_features,\n",
    "                                                            item_features=item_indicator_features)\n",
    "            print(check_results(predicted_ranks))\n",
    "\n",
    "            products_df = pd.DataFrame(list(dataset_to_internal_item_ids.items()), columns=['ORIG_CODE', 'SECOND_CODE'])\n",
    "            products_df = pd.merge(products_df, encodings_product, how='inner', left_on='ORIG_CODE', right_on='code')\n",
    "\n",
    "            #tensorrec.TensorRec.save_model(ranking_cf_model, \"George/Model_Parts/recommender_\"+str(i)+\"/\") -- Optional for storage \n",
    "            #print('Model Saved')\n",
    "            print('Begin Scoring')\n",
    "        \n",
    "            #ranking_cf_model= tensorrec.TensorRec.load_model( \"George/Model_Parts/\")\n",
    "            \n",
    "            def scoring_recommender_baseline(num_reccs):\n",
    "                predicted_ranks_df = pd.DataFrame(predicted_ranks)\n",
    "                df1 = predicted_ranks_df.lt(num_reccs +1, 0)\n",
    "                print('Picked the first ' +str(num_reccs)+ ' products for each customer')\n",
    "                print(df1)\n",
    "                df1 = df1.apply(lambda x: ', '.join(x.index[x].astype(str)),axis=1)\n",
    "                df2 = pd.DataFrame(df1).reset_index()\n",
    "                df2.columns = ['SUB_CODE','products']\n",
    "                print(df2)\n",
    "                df3 = explode(df2.assign(products=df2.products.str.split(',')), 'products')\n",
    "                df3['products'] = df3['products'].astype(int)\n",
    "                print(df3)\n",
    "\n",
    "                products_df = pd.DataFrame(list(dataset_to_internal_item_ids.items()), columns=['ORIG_CODE', 'SECOND_CODE'])\n",
    "                products_df = pd.merge(products_df, encodings_product, how='inner', left_on='ORIG_CODE', right_on='code')\n",
    "                products_df = products_df.drop(columns=['SECOND_CODE', 'code'])\n",
    "                print(products_df)\n",
    "\n",
    "                df4 = pd.merge(df3, products_df, how='left', left_on='products', right_on='ORIG_CODE')\n",
    "                df4 = df4.drop(columns=['products', 'ORIG_CODE'])\n",
    "                df4 = pd.merge(df4, encodings_user, how='left', left_on='SUB_CODE', right_on='code_user')\n",
    "                df4 = df4.drop(columns=['SUB_CODE', 'code_user'])\n",
    "                df4 = df4[['SUB_ID','MARKETING_NAME']]\n",
    "\n",
    "                df4 = pd.DataFrame(df4.groupby('SUB_ID')['MARKETING_NAME'].apply(lambda x: \"{%s}\" % ', '.join(x)))\n",
    "                print(df4)\n",
    "                df4.to_csv('George/Model_Parts/scores_'+str(i)+'/scored_set_baseline.csv')\n",
    "                print('Finished scoring for Baseline Model batch #', i)\n",
    "                \n",
    "            def scoring_new_devices_only(num_reccs):\n",
    "                #ranking_cf_model= tensorrec.TensorRec.load_model( \"George/Model_Parts/Tensorrec0/\")\n",
    "                predicted_ranks_df = pd.DataFrame(predicted_ranks)\n",
    "                df1 = predicted_ranks_df.lt(num_reccs +1, 0)\n",
    "                print('Picked the first ' +str(num_reccs)+ ' products for each customer')\n",
    "                print(df1)\n",
    "                df1 = df1.apply(lambda x: ', '.join(x.index[x].astype(str)),axis=1)\n",
    "                df2 = pd.DataFrame(df1).reset_index()\n",
    "                df2.columns = ['SUB_CODE','products']\n",
    "                print(df2)\n",
    "                df3 = explode(df2.assign(products=df2.products.str.split(',')), 'products')\n",
    "                df3['products'] = df3['products'].astype(int)\n",
    "                print(df3)\n",
    "\n",
    "                df3_3 = pd.merge(df3, max_cust_year_prod, how='left', left_on=['SUB_CODE'], right_on=['code_user'])\n",
    "                df3_3.columns = ['SUB_CODE', 'products', 'code_user', 'YEAR_OUT_MAX']\n",
    "                df3_3.reset_index()\n",
    "                df3_3 = pd.merge(df3_3, max_dev_year_prod, how='left', left_on=['products'], right_on=['code'])\n",
    "                df3_3 = df3_3.fillna(0)\n",
    "                df3_3 = df3_3[df3_3['YEAR_OUT'] > df3_3['YEAR_OUT_MAX']]\n",
    "                del df3_3['YEAR_OUT_MAX']\n",
    "                del df3_3['YEAR_OUT']\n",
    "                del df3_3['code_user']\n",
    "                del df3_3['code']\n",
    "                print(df3_3)\n",
    "\n",
    "                df3_2 = pd.merge(df3_3, existing_products, how='left', left_on=['SUB_CODE', 'products'], right_on=['code_user','code'])\n",
    "                df3_2 = df3_2.fillna('keep')\n",
    "                df3_2 = df3_2.loc[df3_2['code_user'] == 'keep']\n",
    "                df3_2 = df3_2[['SUB_CODE','products']]\n",
    "                print(df3_2)\n",
    "\n",
    "                products_df = pd.DataFrame(list(dataset_to_internal_item_ids.items()), columns=['ORIG_CODE', 'SECOND_CODE'])\n",
    "                products_df = pd.merge(products_df, encodings_product, how='inner', left_on='ORIG_CODE', right_on='code')\n",
    "                products_df = products_df.drop(columns=['SECOND_CODE', 'code'])\n",
    "                print(products_df)\n",
    "\n",
    "                df4 = pd.merge(df3_2, products_df, how='left', left_on='products', right_on='ORIG_CODE')\n",
    "                df4 = df4.drop(columns=['products', 'ORIG_CODE'])\n",
    "                df4 = pd.merge(df4, encodings_user, how='left', left_on='SUB_CODE', right_on='code_user')\n",
    "                df4 = df4.drop(columns=['SUB_CODE', 'code_user'])\n",
    "                df4 = df4[['SUB_ID','MARKETING_NAME']]\n",
    "\n",
    "\n",
    "                df4 = pd.DataFrame(df4.groupby('SUB_ID')['MARKETING_NAME'].apply(lambda x: \"{%s}\" % ', '.join(x)))\n",
    "                print(df4)\n",
    "                df4.to_csv('George/Model_Parts/scores_'+str(i)+'/scored_set_new.csv')\n",
    "                print('Finished scoring for New Devices Model batch #', i)\n",
    "                \n",
    "            def scoring_recommender_os_devs(num_reccs):\n",
    "                #ranking_cf_model= tensorrec.TensorRec.load_model( \"George/Model_Parts/Tensorrec0/\")\n",
    "                predicted_ranks_df = pd.DataFrame(predicted_ranks)\n",
    "                df1 = predicted_ranks_df.lt(num_reccs +1, 0)\n",
    "                print('Picked the first ' +str(num_reccs)+ ' products for each customer')\n",
    "                print(df1)\n",
    "                df1 = df1.apply(lambda x: ', '.join(x.index[x].astype(str)),axis=1)\n",
    "                df2 = pd.DataFrame(df1).reset_index()\n",
    "                df2.columns = ['SUB_CODE','products']\n",
    "                print(df2)\n",
    "                df3 = explode(df2.assign(products=df2.products.str.split(',')), 'products')\n",
    "                df3['products'] = df3['products'].astype(int)\n",
    "                print(df3)\n",
    "\n",
    "                df3_3 = pd.merge(df3, max_cust_os, how='left', left_on=['SUB_CODE'], right_on=['code_user'])\n",
    "                df3_3.columns = ['SUB_CODE', 'products', 'code_user', 'USER_IOS']\n",
    "                df3_3.reset_index()\n",
    "                df3_3 = pd.merge(df3_3, max_product_os, how='left', left_on=['products'], right_on=['code'])\n",
    "                df3_3 = df3_3.fillna(0)\n",
    "\n",
    "                df3_3.head()\n",
    "\n",
    "                df3_4 = df3_3[df3_3['USER_IOS'] == df3_3['IOS']]\n",
    "                del df3_4['IOS']\n",
    "                del df3_4['USER_IOS']\n",
    "                del df3_4['code_user']\n",
    "                del df3_4['code']\n",
    "                print(df3_4)\n",
    "\n",
    "                df3_2 = pd.merge(df3_4, existing_products, how='left', left_on=['SUB_CODE', 'products'], right_on=['code_user','code'])\n",
    "                df3_2 = df3_2.fillna('keep')\n",
    "                df3_2 = df3_2.loc[df3_2['code_user'] == 'keep']\n",
    "                df3_2 = df3_2[['SUB_CODE','products']]\n",
    "                print(df3_2)\n",
    "\n",
    "                products_df = pd.DataFrame(list(dataset_to_internal_item_ids.items()), columns=['ORIG_CODE', 'SECOND_CODE'])\n",
    "                products_df = pd.merge(products_df, encodings_product, how='inner', left_on='ORIG_CODE', right_on='code')\n",
    "                products_df = products_df.drop(columns=['SECOND_CODE', 'code'])\n",
    "                print(products_df)\n",
    "\n",
    "                df4 = pd.merge(df3_2, products_df, how='left', left_on='products', right_on='ORIG_CODE')\n",
    "                df4 = df4.drop(columns=['products', 'ORIG_CODE'])\n",
    "                df4 = pd.merge(df4, encodings_user, how='left', left_on='SUB_CODE', right_on='code_user')\n",
    "                df4 = df4.drop(columns=['SUB_CODE', 'code_user'])\n",
    "                df4 = df4[['SUB_ID','MARKETING_NAME']]\n",
    "\n",
    "\n",
    "                df5 = pd.DataFrame(df4.groupby('SUB_ID')['MARKETING_NAME'].apply(lambda x: \"{%s}\" % ', '.join(x)))\n",
    "                print(df5)\n",
    "                df5.to_csv('George/Model_Parts/scores_'+str(i)+'/scored_set_os.csv')\n",
    "                print('Finished scoring for Same OS Model batch #', i)\n",
    "                \n",
    "            def scoring_recommender_complementary_devs(num_reccs):\n",
    "                #ranking_cf_model= tensorrec.TensorRec.load_model( \"George/Model_Parts/Tensorrec0/\")\n",
    "                predicted_ranks_df = pd.DataFrame(predicted_ranks)\n",
    "                df1 = predicted_ranks_df.lt(num_reccs +1, 0)\n",
    "                print('Picked the first ' +str(num_reccs)+ ' products for each customer')\n",
    "                print(df1)\n",
    "                df1 = df1.apply(lambda x: ', '.join(x.index[x].astype(str)),axis=1)\n",
    "                df2 = pd.DataFrame(df1).reset_index()\n",
    "                df2.columns = ['SUB_CODE','products']\n",
    "                print(df2)\n",
    "                df3 = explode(df2.assign(products=df2.products.str.split(',')), 'products')\n",
    "                df3['products'] = df3['products'].astype(int)\n",
    "                print(df3)\n",
    "\n",
    "                df3_3 = pd.merge(df3, max_product_type, how='left', left_on=['products'], right_on=['code'])\n",
    "                df3_3.head()\n",
    "\n",
    "                df3_4 = df3_3.loc[df3_3['DEVICE_TYPE'].isin(['Tablet','Wearable'])]\n",
    "\n",
    "\n",
    "                print(df3_4.head())\n",
    "\n",
    "                del df3_4['code']\n",
    "                del df3_4['DEVICE_TYPE']\n",
    "\n",
    "\n",
    "                df3_2 = pd.merge(df3_4, existing_products, how='left', left_on=['SUB_CODE', 'products'], right_on=['code_user','code'])\n",
    "                df3_2 = df3_2.fillna('drop')\n",
    "                df3_2 = df3_2.loc[df3_2['code_user'] != 'drop']\n",
    "                df3_2 = df3_2[['SUB_CODE','products']]\n",
    "                print(df3_2)\n",
    "\n",
    "                products_df = pd.DataFrame(list(dataset_to_internal_item_ids.items()), columns=['ORIG_CODE', 'SECOND_CODE'])\n",
    "                products_df = pd.merge(products_df, encodings_product, how='inner', left_on='ORIG_CODE', right_on='code')\n",
    "                products_df = products_df.drop(columns=['SECOND_CODE', 'code'])\n",
    "                print(products_df)\n",
    "\n",
    "                df4 = pd.merge(df3_2, products_df, how='left', left_on='products', right_on='ORIG_CODE')\n",
    "                df4 = df4.drop(columns=['products', 'ORIG_CODE'])\n",
    "                df4 = pd.merge(df4, encodings_user, how='left', left_on='SUB_CODE', right_on='code_user')\n",
    "                df4 = df4.drop(columns=['SUB_CODE', 'code_user'])\n",
    "                df4 = df4[['SUB_ID','MARKETING_NAME']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                df4 = pd.DataFrame(df4.groupby('SUB_ID')['MARKETING_NAME'].apply(lambda x: \"{%s}\" % ', '.join(x)))\n",
    "                print(df4)\n",
    "                df4.to_csv('George/Model_Parts/scores_'+str(i)+'/scored_set_comp.csv')\n",
    "                print('Finished scoring for Complementary Model batch #', i)\n",
    "                \n",
    "            def scoring_recommender_baseline_v2(num_reccs):\n",
    "                #ranking_cf_model= tensorrec.TensorRec.load_model( \"George/Model_Parts/Tensorrec0/\")\n",
    "                predicted_ranks_df = pd.DataFrame(predicted_ranks)\n",
    "                df1 = predicted_ranks_df.lt(num_reccs +1, 0)\n",
    "                print('Picked the first ' +str(num_reccs)+ ' products for each customer')\n",
    "                print(df1)\n",
    "                df1 = df1.apply(lambda x: ', '.join(x.index[x].astype(str)),axis=1)\n",
    "                df2 = pd.DataFrame(df1).reset_index()\n",
    "                df2.columns = ['SUB_CODE','products']\n",
    "                print(df2)\n",
    "                df3 = explode(df2.assign(products=df2.products.str.split(',')), 'products')\n",
    "                df3['products'] = df3['products'].astype(int)\n",
    "                print(df3)\n",
    "                df3_2 = pd.merge(df3, existing_products, how='left', left_on=['SUB_CODE', 'products'], right_on=['code_user','code'])\n",
    "                df3_2 = df3_2.fillna('keep')\n",
    "                df3_2 = df3_2.loc[df3_2['code_user'] == 'keep']\n",
    "                df3_2 = df3_2[['SUB_CODE','products']]\n",
    "\n",
    "                products_df = pd.DataFrame(list(dataset_to_internal_item_ids.items()), columns=['ORIG_CODE', 'SECOND_CODE'])\n",
    "                products_df = pd.merge(products_df, encodings_product, how='inner', left_on='ORIG_CODE', right_on='code')\n",
    "                products_df = products_df.drop(columns=['SECOND_CODE', 'code'])\n",
    "                print(products_df)\n",
    "\n",
    "                df4 = pd.merge(df3_2, products_df, how='left', left_on='products', right_on='ORIG_CODE')\n",
    "                df4 = df4.drop(columns=['products', 'ORIG_CODE'])\n",
    "                df4 = pd.merge(df4, encodings_user, how='left', left_on='SUB_CODE', right_on='code_user')\n",
    "                df4 = df4.drop(columns=['SUB_CODE', 'code_user'])\n",
    "                df4 = df4[['SUB_ID','MARKETING_NAME']]\n",
    "\n",
    "\n",
    "                df4 = pd.DataFrame(df4.groupby('SUB_ID')['MARKETING_NAME'].apply(lambda x: \"{%s}\" % ', '.join(x)))\n",
    "                print(df4)\n",
    "                df4.to_csv('George/Model_Parts/scores_'+str(i)+'/scored_set_base_v2.csv')\n",
    "                print('Finished scoring for Baseline v2 Model batch #', i)\n",
    "                \n",
    "            def scoring_recommender_popularity(num_reccs):\n",
    "                #ranking_cf_model= tensorrec.TensorRec.load_model( \"George/Model_Parts/Tensorrec0/\")\n",
    "                predicted_ranks_df = pd.DataFrame(predicted_ranks)\n",
    "                df1 = predicted_ranks_df.lt(num_reccs +1, 0)\n",
    "                print('Picked the first ' +str(num_reccs)+ ' products for each customer')\n",
    "                print(df1)\n",
    "                df1 = df1.apply(lambda x: ', '.join(x.index[x].astype(str)),axis=1)\n",
    "                df2 = pd.DataFrame(df1).reset_index()\n",
    "                df2.columns = ['SUB_CODE','products']\n",
    "                print(df2)\n",
    "                df3 = explode(df2.assign(products=df2.products.str.split(',')), 'products')\n",
    "                df3['products'] = df3['products'].astype(int)\n",
    "                print(df3)\n",
    "\n",
    "\n",
    "                df3_3 = pd.merge(df3, pop_devices2, how='left', left_on=['products'], right_on=['code'])\n",
    "                df3_3.head()\n",
    "\n",
    "                df3_4 = df3_3.loc[df3_3['Popular'] == 1]\n",
    "\n",
    "\n",
    "                print(df3_4.head())\n",
    "\n",
    "                del df3_4['code']\n",
    "                del df3_4['INTERACTIONS']\n",
    "                del df3_4['Popular']\n",
    "\n",
    "                df3_2 = pd.merge(df3_4, existing_products, how='left', left_on=['SUB_CODE', 'products'], right_on=['code_user','code'])\n",
    "                df3_2 = df3_2.fillna('keep')\n",
    "                df3_2 = df3_2.loc[df3_2['code_user'] == 'keep']\n",
    "                df3_2 = df3_2[['SUB_CODE','products']]\n",
    "\n",
    "                products_df = pd.DataFrame(list(dataset_to_internal_item_ids.items()), columns=['ORIG_CODE', 'SECOND_CODE'])\n",
    "                products_df = pd.merge(products_df, encodings_product, how='inner', left_on='ORIG_CODE', right_on='code')\n",
    "                products_df = products_df.drop(columns=['SECOND_CODE', 'code'])\n",
    "                print(products_df)\n",
    "\n",
    "                df4 = pd.merge(df3_2, products_df, how='left', left_on='products', right_on='ORIG_CODE')\n",
    "                df4 = df4.drop(columns=['products', 'ORIG_CODE'])\n",
    "                df4 = pd.merge(df4, encodings_user, how='left', left_on='SUB_CODE', right_on='code_user')\n",
    "                df4 = df4.drop(columns=['SUB_CODE', 'code_user'])\n",
    "                df4 = df4[['SUB_ID','MARKETING_NAME']]\n",
    "\n",
    "\n",
    "                df4 = pd.DataFrame(df4.groupby('SUB_ID')['MARKETING_NAME'].apply(lambda x: \"{%s}\" % ', '.join(x)))\n",
    "                print(df4)\n",
    "                df4.to_csv('George/Model_Parts/scores_'+str(i)+'/scored_set_pop.csv')\n",
    "                print('Finished scoring for Popularity Model batch #', i)\n",
    "            \n",
    "            scoring_recommender_baseline(num_reccs)\n",
    "            \n",
    "            \n",
    "            scoring_recommender_popularity(num_reccs)\n",
    "            \n",
    "            \n",
    "            scoring_recommender_baseline_v2(num_reccs)\n",
    "            \n",
    "            \n",
    "            scoring_recommender_complementary_devs(num_reccs)\n",
    "            \n",
    "            \n",
    "            scoring_new_devices_only(num_reccs)\n",
    "            \n",
    "            \n",
    "            scoring_recommender_os_devs(num_reccs)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch # 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "         Unnamed: 0 REFERENCE_DATE      SUB_ID  \\\n",
      "3000000     3013057  NOT IMPORTANT  1063766267   \n",
      "3000001     3013058  NOT IMPORTANT  1063766282   \n",
      "3000002     3013059  NOT IMPORTANT  1063766282   \n",
      "3000003     3013060  NOT IMPORTANT  1063766287   \n",
      "3000004     3013061  NOT IMPORTANT  1063766289   \n",
      "\n",
      "                           MARKETING_NAME  INTERACTIONS  code  code_user  \\\n",
      "3000000                SONY XPERIA Z5 LTE             1   928    2054076   \n",
      "3000001                    APPLE IPHONE X             1    71    2054077   \n",
      "3000002  SAMSUNG GALAXY S6 EDGE G925F LTE             1   750    2054077   \n",
      "3000003                    APPLE IPHONE 5             1    57    2054078   \n",
      "3000004                    APPLE IPHONE 6             1    60    2054079   \n",
      "\n",
      "         YEAR_OUT DEVICE_TYPE  IOS  \n",
      "3000000    2015.0  Smartphone  0.0  \n",
      "3000001    2017.0  Smartphone  1.0  \n",
      "3000002    2015.0  Smartphone  0.0  \n",
      "3000003    2013.0  Smartphone  1.0  \n",
      "3000004    2014.0  Smartphone  1.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2\n",
      "5563116      0\n",
      "5461839      0\n",
      "4785845      1\n",
      "5204688      1\n",
      "5315396      1\n",
      "5180175      1\n",
      "4257527      1\n",
      "5832469      1\n",
      "4074643      2\n",
      "3060981      2\n",
      "5425313      2\n",
      "3077178      2\n",
      "3089534      2\n",
      "5863744      2\n",
      "4650850      2\n",
      "5846748      2\n",
      "4593189      2\n",
      "3100629      2\n",
      "3174998      2\n",
      "4646911      2\n",
      "4322142      2\n",
      "4199671      2\n",
      "3818642      2\n",
      "4300477      2\n",
      "4528781      2\n",
      "4338684      2\n",
      "5937191      2\n",
      "3340201      2\n",
      "4441757      2\n",
      "3091078      2\n",
      "          ... \n",
      "3175373    797\n",
      "3386222    797\n",
      "3014143    797\n",
      "3004340    797\n",
      "3058903    797\n",
      "3032464    797\n",
      "3104549    797\n",
      "3139006    797\n",
      "3139049    797\n",
      "3139055    797\n",
      "3116774    797\n",
      "3104548    797\n",
      "3116779    797\n",
      "3139056    797\n",
      "3139057    797\n",
      "3012572    797\n",
      "3139015    797\n",
      "3079767    797\n",
      "3091523    797\n",
      "3101085    797\n",
      "3138999    797\n",
      "3139072    797\n",
      "3120046    797\n",
      "3082045    797\n",
      "3120038    797\n",
      "3139086    797\n",
      "3229209    797\n",
      "3042533    797\n",
      "3116781    797\n",
      "3017728    797\n",
      "Name: code, Length: 3000000, dtype: int16\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3000000 entries, 3000000 to 5999999\n",
      "Data columns (total 10 columns):\n",
      "Unnamed: 0        int64\n",
      "REFERENCE_DATE    object\n",
      "SUB_ID            int64\n",
      "MARKETING_NAME    category\n",
      "INTERACTIONS      int64\n",
      "code              int16\n",
      "code_user         int32\n",
      "YEAR_OUT          float64\n",
      "DEVICE_TYPE       object\n",
      "IOS               float64\n",
      "dtypes: category(1), float64(2), int16(1), int32(1), int64(3), object(2)\n",
      "memory usage: 206.0+ MB\n",
      "None\n",
      "Step 3\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3000000 entries, 3000000 to 5999999\n",
      "Data columns (total 2 columns):\n",
      "MARKETING_NAME    category\n",
      "code              int16\n",
      "dtypes: category(1), int16(1)\n",
      "memory usage: 34.4 MB\n",
      "None\n",
      "Step 4\n",
      "                                      MARKETING_NAME  code\n",
      "5461839                    ACER INCORPORATED E320 EU     0\n",
      "4257527                                      ALCATEL     1\n",
      "3008380                                ALCATEL 1066G     2\n",
      "3765296                            ALCATEL 3T 8 INCH     3\n",
      "4785847                                  ALCATEL 3T8     4\n",
      "3019595                           ALCATEL 4G EE WIFI     5\n",
      "3031261                         ALCATEL 4G EE WIFI 2     6\n",
      "3002560                      ALCATEL 4G EE WIFI MINI     7\n",
      "3006984                     ALCATEL 4G EE WIFI MINI2     8\n",
      "3013862                          ALCATEL 4GEE ROUTER     9\n",
      "3123680                        ALCATEL ALCATEL 1 LTE    10\n",
      "3001044                             ALCATEL B-ATHENA    11\n",
      "3038939                           ALCATEL IDOL46055P    12\n",
      "3016956                               ALCATEL KEYONE    13\n",
      "3320259                                 ALCATEL NEON    14\n",
      "3002944                     ALCATEL ONE TOUCH PIXI 3    15\n",
      "3002190                        ALCATEL ONETOUCH1016G    16\n",
      "3002013                             ALCATEL OSPREY 2    17\n",
      "3000012                        ALCATEL OSPREY 2 MINI    18\n",
      "3009028                        ALCATEL PIXI 3 8 INCH    19\n",
      "3000884                       ALCATEL PIXI 4 (4) LTE    20\n",
      "3052320                       ALCATEL PIXI 4 (5) LTE    21\n",
      "3009401                              ALCATEL PIXI A3    22\n",
      "3000902                            ALCATEL POP45051X    23\n",
      "3101288                                ALCATEL ROBIN    24\n",
      "3026122                       ALCATEL SHINELITE5080X    25\n",
      "3018967                                   ALCATEL U5    26\n",
      "3029156                                   APPLE IPAD    27\n",
      "3006624                                 APPLE IPAD 2    28\n",
      "3006625                              APPLE IPAD 2018    29\n",
      "...                                              ...   ...\n",
      "3125175                                SONY XPERIAL2   768\n",
      "3005089                                SONY XPERIAM5   769\n",
      "3025381                               SONY XPERIAXA1   770\n",
      "3051654                          SONY XPERIAXA1ULTRA   771\n",
      "3003242                               SONY XPERIAXA2   772\n",
      "3017423                          SONY XPERIAXA2ULTRA   773\n",
      "3061340                           SONY XPERIAXAULTRA   774\n",
      "3001335                               SONY XPERIAZ3+   775\n",
      "3466146                     TCT MOBILE ALCATEL 1010X   776\n",
      "3592936                     TCT MOBILE ALCATEL 3040G   777\n",
      "3030921             TCT MOBILE ALCATEL ONE TOUCH 665   778\n",
      "3113213  TCT MOBILE ALCATEL ONE TOUCH IDOL 2 MINI S\\   779\n",
      "3065217           TCT MOBILE ALCATEL ONETOUCH IDOL 3   780\n",
      "3083071                            TCT MOBILE IDOL S   781\n",
      "3014438                             TCT MOBILE L800Z   782\n",
      "3000162                            TCT MOBILE OSPREY   783\n",
      "3039994                            TCT MOBILE POP 7S   784\n",
      "3025455                            TCT MOBILE POP S3   785\n",
      "3001720                             TCT MOBILE Y800Z   786\n",
      "3124092                                ZTE AXON7MINI   787\n",
      "3009810                                  ZTE BLADEV6   788\n",
      "3095182                                 ZTE BLADEV8\\   789\n",
      "3003371                               ZTE EE JAY LTE   790\n",
      "3231898                                  ZTE EE ROOK   791\n",
      "3187546                                    ZTE GN295   792\n",
      "4351379                                    ZTE GR221   793\n",
      "3000377                                    ZTE MF192   794\n",
      "3006961                                    ZTE MF637   795\n",
      "3002655                           ZTE MOBILEVIVACITY   796\n",
      "3004340                                    ZTE ZEST2   797\n",
      "\n",
      "[798 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5\n",
      "3000000          0\n",
      "3000001          1\n",
      "3000002          1\n",
      "3000003          2\n",
      "3000004          3\n",
      "3000005          3\n",
      "3000006          4\n",
      "3000007          4\n",
      "3000008          5\n",
      "3000009          5\n",
      "3000011          6\n",
      "3000010          6\n",
      "3000012          7\n",
      "3000013          8\n",
      "3000014          8\n",
      "3000015          9\n",
      "3000016         10\n",
      "3000017         11\n",
      "3000018         12\n",
      "3000019         13\n",
      "3000020         14\n",
      "3000021         15\n",
      "3000022         16\n",
      "3000023         17\n",
      "3000024         17\n",
      "3000025         18\n",
      "3000026         19\n",
      "3000027         19\n",
      "3000028         20\n",
      "3000029         20\n",
      "            ...   \n",
      "5999970    2006072\n",
      "5999971    2006073\n",
      "5999972    2006073\n",
      "5999973    2006074\n",
      "5999975    2006075\n",
      "5999974    2006075\n",
      "5999976    2006076\n",
      "5999977    2006077\n",
      "5999978    2006078\n",
      "5999979    2006078\n",
      "5999980    2006079\n",
      "5999981    2006079\n",
      "5999982    2006080\n",
      "5999983    2006081\n",
      "5999984    2006082\n",
      "5999985    2006082\n",
      "5999986    2006083\n",
      "5999987    2006083\n",
      "5999989    2006084\n",
      "5999988    2006084\n",
      "5999990    2006085\n",
      "5999992    2006086\n",
      "5999991    2006086\n",
      "5999993    2006087\n",
      "5999994    2006088\n",
      "5999995    2006088\n",
      "5999996    2006089\n",
      "5999997    2006089\n",
      "5999998    2006090\n",
      "5999999    2006091\n",
      "Name: code_user, Length: 3000000, dtype: int32\n",
      "Step 6\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3000000 entries, 3000000 to 5999999\n",
      "Data columns (total 2 columns):\n",
      "SUB_ID       category\n",
      "code_user    int32\n",
      "dtypes: category(1), int32(1)\n",
      "memory usage: 141.1 MB\n",
      "None\n",
      "Step 7\n",
      "             SUB_ID  code_user\n",
      "3000000  1063766267          0\n",
      "3000001  1063766282          1\n",
      "3000003  1063766287          2\n",
      "3000004  1063766289          3\n",
      "3000006  1063766291          4\n",
      "3000008  1063766296          5\n",
      "3000010  1063766300          6\n",
      "3000012  1063766307          7\n",
      "3000013  1063766308          8\n",
      "3000015  1063766310          9\n",
      "3000016  1063766318         10\n",
      "3000017  1063766321         11\n",
      "3000018  1063766324         12\n",
      "3000019  1063766325         13\n",
      "3000020  1063766330         14\n",
      "3000021  1063766331         15\n",
      "3000022  1063766333         16\n",
      "3000023  1063766339         17\n",
      "3000025  1063766348         18\n",
      "3000026  1063766349         19\n",
      "3000028  1063766353         20\n",
      "3000030  1063766354         21\n",
      "3000031  1063766355         22\n",
      "3000033  1063766361         23\n",
      "3000034  1063766362         24\n",
      "3000036  1063766365         25\n",
      "3000037  1063766388         26\n",
      "3000038  1063766389         27\n",
      "3000040  1063766390         28\n",
      "3000041  1063766391         29\n",
      "...             ...        ...\n",
      "5999958  1099814761    2006062\n",
      "5999959  1099814770    2006063\n",
      "5999960  1099814771    2006064\n",
      "5999961  1099814779    2006065\n",
      "5999963  1099814780    2006066\n",
      "5999964  1099814787    2006067\n",
      "5999965  1099814788    2006068\n",
      "5999966  1099814790    2006069\n",
      "5999967  1099814791    2006070\n",
      "5999968  1099814792    2006071\n",
      "5999970  1099814800    2006072\n",
      "5999971  1099814801    2006073\n",
      "5999973  1099814802    2006074\n",
      "5999974  1099814803    2006075\n",
      "5999976  1099814806    2006076\n",
      "5999977  1099814809    2006077\n",
      "5999978  1099814810    2006078\n",
      "5999980  1099814812    2006079\n",
      "5999982  1099814815    2006080\n",
      "5999983  1099814817    2006081\n",
      "5999984  1099814820    2006082\n",
      "5999986  1099814822    2006083\n",
      "5999988  1099814824    2006084\n",
      "5999990  1099814826    2006085\n",
      "5999991  1099814827    2006086\n",
      "5999993  1099814830    2006087\n",
      "5999994  1099814831    2006088\n",
      "5999996  1099814838    2006089\n",
      "5999998  1099814847    2006090\n",
      "5999999  1099814849    2006091\n",
      "\n",
      "[2006092 rows x 2 columns]\n",
      "Step 8\n",
      "         Unnamed: 0 REFERENCE_DATE      SUB_ID  INTERACTIONS  code  YEAR_OUT  \\\n",
      "3000000     3013057  NOT IMPORTANT  1063766267             1   762    2015.0   \n",
      "3000001     3013058  NOT IMPORTANT  1063766282             1    70    2017.0   \n",
      "3000002     3013059  NOT IMPORTANT  1063766282             1   624    2015.0   \n",
      "3000003     3013060  NOT IMPORTANT  1063766287             1    56    2013.0   \n",
      "3000004     3013061  NOT IMPORTANT  1063766289             1    59    2014.0   \n",
      "\n",
      "        DEVICE_TYPE  IOS  \n",
      "3000000  Smartphone  0.0  \n",
      "3000001  Smartphone  1.0  \n",
      "3000002  Smartphone  0.0  \n",
      "3000003  Smartphone  1.0  \n",
      "3000004  Smartphone  1.0  \n",
      "Step 9\n",
      "             SUB_ID  code  INTERACTIONS REFERENCE_DATE\n",
      "5999998  1099814847   618             1  NOT IMPORTANT\n",
      "5999999  1099814849    69             1  NOT IMPORTANT\n",
      "Step 10\n",
      "Raw ratings example:\n",
      "['SUB_ID', 'code', 'INTERACTIONS', 'REFERENCE_DATE']\n",
      "[0, 0, 1.0, 'NOT IMPORTANT']\n",
      "Step 11\n",
      "2400000 train ratings, 600000 test ratings\n",
      "Step 12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8153458f7a71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_creation_and_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-24631cb7a51f>\u001b[0m in \u001b[0;36mmodel_creation_and_scoring\u001b[0;34m(num_reccs)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step 12'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# Create sparse matrices of interaction data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0msparse_train_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteractions_list_to_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0msparse_test_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteractions_list_to_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-24631cb7a51f>\u001b[0m in \u001b[0;36minteractions_list_to_sparse_matrix\u001b[0;34m(interactions)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# This method converts a list of (user, item, rating, time) to a sparse matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0minteractions_list_to_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0musers_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minteractions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 return sparse.coo_matrix((ratings_column, (users_column, items_column)),\n\u001b[1;32m    126\u001b[0m                                          shape=(n_users, n_items))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_creation_and_scoring(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARIFF_CODE</th>\n",
       "      <th>DATA</th>\n",
       "      <th>MINUTES</th>\n",
       "      <th>SMS</th>\n",
       "      <th>UPFRONT_COST</th>\n",
       "      <th>MONTHLY_COST</th>\n",
       "      <th>JOURNEY_TYPE</th>\n",
       "      <th>MP_IDENTIFIER</th>\n",
       "      <th>DEVICE_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X19B24H41</td>\n",
       "      <td>100000</td>\n",
       "      <td>Unlimited</td>\n",
       "      <td>Unlimited</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>Upgrade</td>\n",
       "      <td>iphone-6s-128gb-silver</td>\n",
       "      <td>IPHONE 6S 128GB SILVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X19B24H05</td>\n",
       "      <td>10000</td>\n",
       "      <td>Unlimited</td>\n",
       "      <td>Unlimited</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Upgrade</td>\n",
       "      <td>iphone-6s-plus-128gb-silver</td>\n",
       "      <td>IPHONE 6S PLUS 128GB SILVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X19A24H57</td>\n",
       "      <td>30000</td>\n",
       "      <td>Unlimited</td>\n",
       "      <td>Unlimited</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Upgrade</td>\n",
       "      <td>iphone-6s-128gb-rose-gold</td>\n",
       "      <td>IPHONE 6S 128GB ROSE GOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>X19B24H22</td>\n",
       "      <td>60000</td>\n",
       "      <td>Unlimited</td>\n",
       "      <td>Unlimited</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Upgrade</td>\n",
       "      <td>iphone-7-32gb-black</td>\n",
       "      <td>IPHONE 7 32GB BLACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>X19A24H63</td>\n",
       "      <td>60000</td>\n",
       "      <td>Unlimited</td>\n",
       "      <td>Unlimited</td>\n",
       "      <td>300.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Upgrade</td>\n",
       "      <td>iphone-7-128gb-silver</td>\n",
       "      <td>IPHONE 7 128GB SILVER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARIFF_CODE    DATA    MINUTES        SMS  UPFRONT_COST  MONTHLY_COST  \\\n",
       "7    X19B24H41  100000  Unlimited  Unlimited           0.0         104.0   \n",
       "8    X19B24H05   10000  Unlimited  Unlimited           0.0          74.0   \n",
       "9    X19A24H57   30000  Unlimited  Unlimited           0.0          74.0   \n",
       "10   X19B24H22   60000  Unlimited  Unlimited           0.0          59.0   \n",
       "11   X19A24H63   60000  Unlimited  Unlimited         300.0          41.0   \n",
       "\n",
       "   JOURNEY_TYPE                MP_IDENTIFIER                  DEVICE_NAME  \n",
       "7       Upgrade       iphone-6s-128gb-silver       IPHONE 6S 128GB SILVER  \n",
       "8       Upgrade  iphone-6s-plus-128gb-silver  IPHONE 6S PLUS 128GB SILVER  \n",
       "9       Upgrade    iphone-6s-128gb-rose-gold    IPHONE 6S 128GB ROSE GOLD  \n",
       "10      Upgrade          iphone-7-32gb-black          IPHONE 7 32GB BLACK  \n",
       "11      Upgrade        iphone-7-128gb-silver        IPHONE 7 128GB SILVER  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Digital Price book  -- to be replaced with non-static when pipeline is implemented\n",
    "bucket='bt-data-science-playground' # Or whatever you called your bucket\n",
    "data_key = 'GP/digital_pricebook.csv' # Where the file is within your bucket\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "digital_pricebook = pd.read_csv(data_location)\n",
    "digital_pricebook = digital_pricebook[pd.notnull(digital_pricebook['DEVICE_NAME'])]\n",
    "digital_pricebook['DEVICE_NAME'] = digital_pricebook['DEVICE_NAME'].str.upper()\n",
    "\n",
    "digital_pricebook = digital_pricebook.fillna(0)\n",
    "\n",
    "digital_pricebook = digital_pricebook[digital_pricebook['JOURNEY_TYPE'] == 'Upgrade']\n",
    "digital_pricebook['key'] = 0 \n",
    "\n",
    "digital_pricebook.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Customer Predicted Usage -- to be replaced with non-static when pipeline is implemented\n",
    "bucket='bt-data-science-playground' # Or whatever you called your bucket\n",
    "data_key = 'GP/cust_pred_usage.csv' # Where the file is within your bucket\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "cust_pred_usage = pd.read_csv(data_location)\n",
    "cust_pred_usage = cust_pred_usage[['SUB_ID','PRED_USAGE']]\n",
    "cust_pred_usage['SUB_ID'] = np.int64(cust_pred_usage['SUB_ID'])\n",
    "cust_pred_usage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_scoring_w_tariff(table_name):\n",
    "    for i in range(0,6): #loops through dataset chunks to create model & score for each:\n",
    "        location = 'George/Model_Parts/scores_' + str(i) + '/' + table_name +'.csv'\n",
    "        d_score = pd.read_csv(location)\n",
    "        d_score['MARKETING_NAME'] = d_score['MARKETING_NAME'].str.replace('{','')\n",
    "        d_score['MARKETING_NAME'] = d_score['MARKETING_NAME'].str.replace('}','')\n",
    "        d_score['MARKETING_NAME'] = d_score['MARKETING_NAME'].str.replace('LTE','')\n",
    "        print(d_score.head())\n",
    "\n",
    "        d_score =  pd.DataFrame(d_score.MARKETING_NAME.str.split(',').tolist(), index=d_score.SUB_ID).stack()\n",
    "        print(d_score.head())\n",
    "\n",
    "        d_score = d_score.reset_index([0, 'SUB_ID'])\n",
    "        d_score.columns = ['SUB_ID', 'MARKETING_NAME']\n",
    "        print(d_score.head())\n",
    "\n",
    "        recc_devices = pd.DataFrame(d_score['MARKETING_NAME'].unique())\n",
    "        recc_devices.columns = ['MARKETING_NAME']\n",
    "        print(recc_devices.nunique())\n",
    "\n",
    "        recc_devices['key'] = 0 \n",
    "\n",
    "        recc_devices2 = recc_devices.merge(digital_pricebook, how='outer' , on ='key')\n",
    "        recc_devices2 = recc_devices2.dropna()\n",
    "        print(recc_devices2.head())\n",
    "\n",
    "        recc_devices2['MARKETING_NAME'] = recc_devices2['MARKETING_NAME'].astype(str)\n",
    "        recc_devices2['MARKETING_NAME'] = recc_devices2['MARKETING_NAME'].map(lambda x: x.rstrip())\n",
    "        recc_devices2['DEVICE_NAME'] = recc_devices2['DEVICE_NAME'].astype(str)\n",
    "        recc_devices2['DEVICE_NAME'] = recc_devices2['DEVICE_NAME'].map(lambda x: x.rstrip())\n",
    "        print(recc_devices2.info())\n",
    "\n",
    "        recc_devices2['same'] = [x[0] in x[1] for x in zip(recc_devices2['MARKETING_NAME'], recc_devices2['DEVICE_NAME'])]\n",
    "        print(recc_devices2.head())\n",
    "\n",
    "        recc_devices3 = recc_devices2\n",
    "\n",
    "        #recc_devices3['partial_ratio'] = recc_devices3.apply(lambda x: fuzz.partial_ratio(x['MARKETING_NAME'], x['DEVICE_NAME']), axis=1)\n",
    "        #recc_devices3['ratio'] = recc_devices3.apply(lambda x: fuzz.ratio(x['MARKETING_NAME'], x['DEVICE_NAME']), axis=1)\n",
    "        recc_devices3['token_sort_ratio'] = recc_devices3.apply(lambda x: fuzz.token_sort_ratio(x['MARKETING_NAME'], x['DEVICE_NAME']), axis=1)\n",
    "        #recc_devices3['token_set_ratio'] = recc_devices3.apply(lambda x: fuzz.token_set_ratio(x['MARKETING_NAME'], x['DEVICE_NAME']), axis=1)\n",
    "        #recc_devices3['avg_ratio'] = ( recc_devices3['partial_ratio'] + recc_devices3['ratio'] + recc_devices3['token_sort_ratio'] + recc_devices3['token_set_ratio']) / 4 \n",
    "\n",
    "        print(recc_devices3.head())\n",
    "\n",
    "        recc_devices4 = recc_devices3[recc_devices3['token_sort_ratio'] > 70]\n",
    "        recc_devices4['DATA'].replace('Unlimited','99999999',inplace=True)\n",
    "        recc_devices4['DATA'] = pd.to_numeric(recc_devices4['DATA'])\n",
    "        print(recc_devices4.head())\n",
    "\n",
    "        d_score = d_score.merge(cust_pred_usage, how='inner' , on ='SUB_ID')\n",
    "        print(d_score.head())\n",
    "\n",
    "        # Scoring chunk size \n",
    "        n = 100000\n",
    "\n",
    "        # Chunk score dataset \n",
    "        list_df = [d_score[i:i+n] for i in range(0,d_score.shape[0],n)]\n",
    "\n",
    "        #Number of chunks \n",
    "        max_len_list2 = math.ceil(len(d_score)/n) \n",
    "        print(max_len_list2)\n",
    "\n",
    "        scored_base = pd.DataFrame()\n",
    "\n",
    "        for j in range(0,max_len_list2): #loops through dataset chunks to create model & score for each:\n",
    "            if table_name == 'scored_set_comp':\n",
    "                list_df[j]['MARKETING_NAME'] = list_df[j]['MARKETING_NAME'].astype(str)\n",
    "                list_df[j]['MARKETING_NAME'] = list_df[j]['MARKETING_NAME'].map(lambda x: x.rstrip())\n",
    "                list_df[j] = list_df[j].merge(recc_devices4, how='left' , on ='MARKETING_NAME')\n",
    "                #list_df[j] = list_df[j][list_df[j]['DATA'] > list_df[j]['PRED_USAGE']]\n",
    "                idx = list_df[j].groupby(['SUB_ID','MARKETING_NAME'])['DATA'].transform(min) == list_df[j]['DATA']\n",
    "                list_df[j] = list_df[j][idx]\n",
    "                list_df[j] = list_df[j].groupby(['SUB_ID','MARKETING_NAME']).apply(lambda x: x.sample(1)).reset_index(drop=True)\n",
    "                scored_base = scored_base.append(list_df[j])\n",
    "                print(list_df[j].head())\n",
    "            else :\n",
    "                list_df[j]['MARKETING_NAME'] = list_df[j]['MARKETING_NAME'].astype(str)\n",
    "                list_df[j]['MARKETING_NAME'] = list_df[j]['MARKETING_NAME'].map(lambda x: x.rstrip())\n",
    "                list_df[j] = list_df[j].merge(recc_devices4, how='left' , on ='MARKETING_NAME')\n",
    "                list_df[j] = list_df[j][list_df[j]['DATA'] > list_df[j]['PRED_USAGE']]\n",
    "                idx = list_df[j].groupby(['SUB_ID','MARKETING_NAME'])['DATA'].transform(min) == list_df[j]['DATA']\n",
    "                list_df[j] = list_df[j][idx]\n",
    "                list_df[j] = list_df[j].groupby(['SUB_ID','MARKETING_NAME']).apply(lambda x: x.sample(1)).reset_index(drop=True)\n",
    "                scored_base = scored_base.append(list_df[j])\n",
    "                print(list_df[j].head())\n",
    "        scored_base.to_csv('George/Model_Parts/scores_'+str(i)+'/' + table_name +'_final.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SUB_ID MARKETING_NAME\n",
      "0    1006               \n",
      "1    1016               \n",
      "2    1020               \n",
      "3    1025               \n",
      "4    1027               \n",
      "SUB_ID   \n",
      "1006    0    \n",
      "1016    0    \n",
      "1020    0    \n",
      "1025    0    \n",
      "1027    0    \n",
      "dtype: object\n",
      "   SUB_ID MARKETING_NAME\n",
      "0    1006               \n",
      "1    1016               \n",
      "2    1020               \n",
      "3    1025               \n",
      "4    1027               \n",
      "MARKETING_NAME    27\n",
      "dtype: int64\n",
      "  MARKETING_NAME  key TARIFF_CODE    DATA    MINUTES        SMS  UPFRONT_COST  \\\n",
      "0                   0   X19B24H41  100000  Unlimited  Unlimited           0.0   \n",
      "1                   0   X19B24H05   10000  Unlimited  Unlimited           0.0   \n",
      "2                   0   X19A24H57   30000  Unlimited  Unlimited           0.0   \n",
      "3                   0   X19B24H22   60000  Unlimited  Unlimited           0.0   \n",
      "4                   0   X19A24H63   60000  Unlimited  Unlimited         300.0   \n",
      "\n",
      "   MONTHLY_COST JOURNEY_TYPE                MP_IDENTIFIER  \\\n",
      "0         104.0      Upgrade       iphone-6s-128gb-silver   \n",
      "1          74.0      Upgrade  iphone-6s-plus-128gb-silver   \n",
      "2          74.0      Upgrade    iphone-6s-128gb-rose-gold   \n",
      "3          59.0      Upgrade          iphone-7-32gb-black   \n",
      "4          41.0      Upgrade        iphone-7-128gb-silver   \n",
      "\n",
      "                   DEVICE_NAME  \n",
      "0       IPHONE 6S 128GB SILVER  \n",
      "1  IPHONE 6S PLUS 128GB SILVER  \n",
      "2    IPHONE 6S 128GB ROSE GOLD  \n",
      "3          IPHONE 7 32GB BLACK  \n",
      "4        IPHONE 7 128GB SILVER  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1187379 entries, 0 to 1187378\n",
      "Data columns (total 11 columns):\n",
      "MARKETING_NAME    1187379 non-null object\n",
      "key               1187379 non-null int64\n",
      "TARIFF_CODE       1187379 non-null object\n",
      "DATA              1187379 non-null object\n",
      "MINUTES           1187379 non-null object\n",
      "SMS               1187379 non-null object\n",
      "UPFRONT_COST      1187379 non-null float64\n",
      "MONTHLY_COST      1187379 non-null float64\n",
      "JOURNEY_TYPE      1187379 non-null object\n",
      "MP_IDENTIFIER     1187379 non-null object\n",
      "DEVICE_NAME       1187379 non-null object\n",
      "dtypes: float64(2), int64(1), object(8)\n",
      "memory usage: 108.7+ MB\n",
      "None\n",
      "  MARKETING_NAME  key TARIFF_CODE    DATA    MINUTES        SMS  UPFRONT_COST  \\\n",
      "0                   0   X19B24H41  100000  Unlimited  Unlimited           0.0   \n",
      "1                   0   X19B24H05   10000  Unlimited  Unlimited           0.0   \n",
      "2                   0   X19A24H57   30000  Unlimited  Unlimited           0.0   \n",
      "3                   0   X19B24H22   60000  Unlimited  Unlimited           0.0   \n",
      "4                   0   X19A24H63   60000  Unlimited  Unlimited         300.0   \n",
      "\n",
      "   MONTHLY_COST JOURNEY_TYPE                MP_IDENTIFIER  \\\n",
      "0         104.0      Upgrade       iphone-6s-128gb-silver   \n",
      "1          74.0      Upgrade  iphone-6s-plus-128gb-silver   \n",
      "2          74.0      Upgrade    iphone-6s-128gb-rose-gold   \n",
      "3          59.0      Upgrade          iphone-7-32gb-black   \n",
      "4          41.0      Upgrade        iphone-7-128gb-silver   \n",
      "\n",
      "                   DEVICE_NAME  same  \n",
      "0       IPHONE 6S 128GB SILVER  True  \n",
      "1  IPHONE 6S PLUS 128GB SILVER  True  \n",
      "2    IPHONE 6S 128GB ROSE GOLD  True  \n",
      "3          IPHONE 7 32GB BLACK  True  \n",
      "4        IPHONE 7 128GB SILVER  True  \n",
      "  MARKETING_NAME  key TARIFF_CODE    DATA    MINUTES        SMS  UPFRONT_COST  \\\n",
      "0                   0   X19B24H41  100000  Unlimited  Unlimited           0.0   \n",
      "1                   0   X19B24H05   10000  Unlimited  Unlimited           0.0   \n",
      "2                   0   X19A24H57   30000  Unlimited  Unlimited           0.0   \n",
      "3                   0   X19B24H22   60000  Unlimited  Unlimited           0.0   \n",
      "4                   0   X19A24H63   60000  Unlimited  Unlimited         300.0   \n",
      "\n",
      "   MONTHLY_COST JOURNEY_TYPE                MP_IDENTIFIER  \\\n",
      "0         104.0      Upgrade       iphone-6s-128gb-silver   \n",
      "1          74.0      Upgrade  iphone-6s-plus-128gb-silver   \n",
      "2          74.0      Upgrade    iphone-6s-128gb-rose-gold   \n",
      "3          59.0      Upgrade          iphone-7-32gb-black   \n",
      "4          41.0      Upgrade        iphone-7-128gb-silver   \n",
      "\n",
      "                   DEVICE_NAME  same  token_sort_ratio  \n",
      "0       IPHONE 6S 128GB SILVER  True                 0  \n",
      "1  IPHONE 6S PLUS 128GB SILVER  True                 0  \n",
      "2    IPHONE 6S 128GB ROSE GOLD  True                 0  \n",
      "3          IPHONE 7 32GB BLACK  True                 0  \n",
      "4        IPHONE 7 128GB SILVER  True                 0  \n",
      "                MARKETING_NAME  key TARIFF_CODE    DATA    MINUTES        SMS  \\\n",
      "263921  SAMSUNG GALAXY YOUNG 2    0   X19A24H85  100000  Unlimited  Unlimited   \n",
      "264012  SAMSUNG GALAXY YOUNG 2    0   X19A24H46   10000  Unlimited  Unlimited   \n",
      "264098  SAMSUNG GALAXY YOUNG 2    0   X19A24H70   60000  Unlimited  Unlimited   \n",
      "264179  SAMSUNG GALAXY YOUNG 2    0   X19A24H97   60000  Unlimited  Unlimited   \n",
      "264191  SAMSUNG GALAXY YOUNG 2    0   X19B24H29   60000  Unlimited  Unlimited   \n",
      "\n",
      "        UPFRONT_COST  MONTHLY_COST JOURNEY_TYPE              MP_IDENTIFIER  \\\n",
      "263921           0.0          84.0      Upgrade  samsung-galaxy-a20e-white   \n",
      "264012           0.0          84.0      Upgrade  samsung-galaxy-a20e-white   \n",
      "264098           0.0          74.0      Upgrade   samsung-galaxy-a40-black   \n",
      "264179           0.0         109.0      Upgrade          samsung-galaxy-a9   \n",
      "264191           0.0          94.0      Upgrade   samsung-galaxy-a40-black   \n",
      "\n",
      "                      DEVICE_NAME   same  token_sort_ratio  \n",
      "263921  SAMSUNG GALAXY A20E WHITE  False                72  \n",
      "264012  SAMSUNG GALAXY A20E WHITE  False                72  \n",
      "264098         SAMSUNG GALAXY A40  False                75  \n",
      "264179          SAMSUNG GALAXY A9  False                77  \n",
      "264191         SAMSUNG GALAXY A40  False                75  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/generic.py:6586: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SUB_ID MARKETING_NAME  PRED_USAGE\n",
      "0    1006                     3300.0\n",
      "1    1016                    11900.0\n",
      "2    1020                    10100.0\n",
      "3    1025                     1400.0\n",
      "4    1027                      500.0\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "       SUB_ID         MARKETING_NAME  PRED_USAGE  key TARIFF_CODE   DATA  \\\n",
      "0  1037363957  SAMSUNG GALAXY TAB S2     19300.0  0.0   X19A24H07  500.0   \n",
      "1  1037950021  SAMSUNG GALAXY TAB S2     11200.0  0.0   X19A24H08  500.0   \n",
      "\n",
      "     MINUTES        SMS  UPFRONT_COST  MONTHLY_COST JOURNEY_TYPE  \\\n",
      "0  Unlimited  Unlimited          30.0          38.0      Upgrade   \n",
      "1  Unlimited  Unlimited         100.0          43.0      Upgrade   \n",
      "\n",
      "        MP_IDENTIFIER         DEVICE_NAME   same  token_sort_ratio  \n",
      "0   samsung-galaxy-a9   SAMSUNG GALAXY A9  False              74.0  \n",
      "1  samsung-galaxy-a80  SAMSUNG GALAXY A80  False              72.0  \n",
      "       SUB_ID         MARKETING_NAME  PRED_USAGE  key TARIFF_CODE    DATA  \\\n",
      "0  1040390541   APPLE IPAD MINI 2019       200.0  0.0   X19A24T06  2000.0   \n",
      "\n",
      "  MINUTES SMS  UPFRONT_COST  MONTHLY_COST JOURNEY_TYPE  \\\n",
      "0       0   0           0.0          34.0      Upgrade   \n",
      "\n",
      "              MP_IDENTIFIER               DEVICE_NAME   same  token_sort_ratio  \n",
      "0  ipad-mini-64gb-gold-2019  IPAD MINI 64GB GOLD 2019  False              73.0  \n",
      "       SUB_ID        MARKETING_NAME  PRED_USAGE  key TARIFF_CODE    DATA  \\\n",
      "0  1047970890  APPLE IPAD MINI 2019       800.0  0.0   X19A24T06  2000.0   \n",
      "\n",
      "  MINUTES SMS  UPFRONT_COST  MONTHLY_COST JOURNEY_TYPE  \\\n",
      "0       0   0           0.0          34.0      Upgrade   \n",
      "\n",
      "              MP_IDENTIFIER               DEVICE_NAME   same  token_sort_ratio  \n",
      "0  ipad-mini-64gb-gold-2019  IPAD MINI 64GB GOLD 2019  False              73.0  \n",
      "       SUB_ID        MARKETING_NAME  PRED_USAGE  key TARIFF_CODE    DATA  \\\n",
      "0  1054002063  APPLE IPAD MINI 2019       200.0  0.0   X19A24T09  2000.0   \n",
      "\n",
      "  MINUTES SMS  UPFRONT_COST  MONTHLY_COST JOURNEY_TYPE  \\\n",
      "0       0   0           0.0          42.5      Upgrade   \n",
      "\n",
      "               MP_IDENTIFIER                DEVICE_NAME   same  \\\n",
      "0  ipad-mini-256gb-gold-2019  IPAD MINI 256GB GOLD 2019  False   \n",
      "\n",
      "   token_sort_ratio  \n",
      "0              71.0  \n",
      "       SUB_ID        MARKETING_NAME  PRED_USAGE  key TARIFF_CODE    DATA  \\\n",
      "0  1062904234  APPLE IPAD MINI 2019      3900.0  0.0   X19A24T05  2000.0   \n",
      "\n",
      "  MINUTES SMS  UPFRONT_COST  MONTHLY_COST JOURNEY_TYPE  \\\n",
      "0       0   0          30.0         31.45      Upgrade   \n",
      "\n",
      "              MP_IDENTIFIER               DEVICE_NAME   same  token_sort_ratio  \n",
      "0  ipad-mini-64gb-gold-2019  IPAD MINI 64GB GOLD 2019  False              73.0  \n",
      "       SUB_ID         MARKETING_NAME  PRED_USAGE  key TARIFF_CODE   DATA  \\\n",
      "0  1063743457  SAMSUNG GALAXY TAB S2      1000.0  0.0   X19A24H06  500.0   \n",
      "\n",
      "     MINUTES        SMS  UPFRONT_COST  MONTHLY_COST JOURNEY_TYPE  \\\n",
      "0  Unlimited  Unlimited          50.0          33.0      Upgrade   \n",
      "\n",
      "       MP_IDENTIFIER        DEVICE_NAME   same  token_sort_ratio  \n",
      "0  samsung-galaxy-a9  SAMSUNG GALAXY A9  False              74.0  \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'George/Model_Parts/scores_1/scored_set_comp.csv' does not exist: b'George/Model_Parts/scores_1/scored_set_comp.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-56346671c638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_scoring_w_tariff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scored_set_comp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-c12fb87fadf9>\u001b[0m in \u001b[0;36mfinal_scoring_w_tariff\u001b[0;34m(table_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#loops through dataset chunks to create model & score for each:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'George/Model_Parts/scores_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtable_name\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0md_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0md_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MARKETING_NAME'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MARKETING_NAME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0md_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MARKETING_NAME'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MARKETING_NAME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'George/Model_Parts/scores_1/scored_set_comp.csv' does not exist: b'George/Model_Parts/scores_1/scored_set_comp.csv'"
     ]
    }
   ],
   "source": [
    "final_scoring_w_tariff('scored_set_comp')\n",
    "final_scoring_w_tariff('scored_set_base_v2')\n",
    "final_scoring_w_tariff('scored_set_baseline')\n",
    "final_scoring_w_tariff('scored_set_new')\n",
    "final_scoring_w_tariff('scored_set_os')\n",
    "final_scoring_w_tariff('scored_set_pop')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
